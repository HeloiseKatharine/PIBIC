# -*- coding: utf-8 -*-
"""Implementação CNN ResNet TCC Gregory v_1_0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a9WgEXBb_2ucNpnHLhUjOtvfV9q-p3X7

Importação das bibliotecas
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import random
import zipfile
import PIL
import pickle
import os
tf.__version__

from google.colab import drive
drive.mount('/content/drive')

path = '/content/drive/MyDrive/TCC/ct_dataset_tcc_gregory_v_1_0.zip'
zip_object = zipfile.ZipFile(file=path, mode='r')
zip_object.extractall('./')
zip_object.close()

"""Importação do modelo com os pesos pré-treinados"""

model = tf.keras.applications.ResNet50(weights='imagenet')

base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)

base_model.summary()

x = base_model.output

x = tf.keras.layers.GlobalAveragePooling2D()(x)

x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
preds = tf.keras.layers.Dense(2, activation='softmax')(x)#saida vai depender de quantas classes estão envolvidas

model = tf.keras.models.Model(inputs = base_model.input, outputs = preds)

model.summary()

for i, layer in enumerate (model.layers):
  print(i, layer.name)

#congelar os pesos para que as camadas anteriores as da minha criação não sejam treinados junto
for layer in model.layers[:175]:#174 até o 0
  layer.trainable = False

for layer in model.layers[175:]:#175 até o final
  layer.trainable = True

#pega cada imagem, faz a leitura e faz o pre processamento exatamente como foi feito na construção do modelo ResNet50
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,
                                                                validation_split = 0.2)#SEPARAÇÃO DOS DADOS

#detecta automaticamente quantas classes vão ter dentro do conjunto de treinamento
train_generator = train_datagen.flow_from_directory('/content/dataset_ct_tcc_gregory_v1',
                                                    target_size = (224,224),
                                                    color_mode = 'rgb',
                                                    batch_size = 32,
                                                    class_mode = 'categorical',
                                                    shuffle = True,
                                                    subset = 'training')

test_generator = train_datagen.flow_from_directory('/content/dataset_ct_tcc_gregory_v1',
                                                    target_size = (224,224),
                                                    color_mode = 'rgb',
                                                    batch_size = 32,
                                                    class_mode = 'categorical',
                                                    shuffle = True,
                                                    subset = 'validation')

model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit_generator(generator = train_generator,
                    validation_data = test_generator,
                    epochs = 10)

model.evaluate_generator(generator=test_generator)

"""Avaliação do modelo"""

acc = history.history['accuracy']
loss = history.history['loss']

plt.figure()
plt.plot(acc, label='Training Accuracy')
plt.ylabel('Accuracy')
plt.title('Training Accuracy')

plt.figure()
plt.plot(loss, label='Training Loss')
plt.ylabel('Loss')
plt.title('Traning Loss')
plt.xlabel('epoch')
plt.show()

acc_val = history.history['val_accuracy']
val_loss = history.history['val_loss']

plt.figure()
plt.plot(acc_val, label='Test Accuracy')
plt.ylabel('Accuracy')
plt.title('Test Accuracy')

plt.figure()
plt.plot(val_loss, label='Test Loss')
plt.ylabel('Loss')
plt.title('Test Loss')
plt.xlabel('epoch')
plt.show()

epochs = range(len(acc))
plt.plot(epochs, acc, 'bo', label= 'Training Accuracy')
plt.plot(epochs, acc_val, 'b', label= 'Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend();

image_test = tf.keras.preprocessing.image.load_img(r'/content/covid2.png', target_size=(224,224))

plt.imshow(image_test)

image_test = tf.keras.preprocessing.image.img_to_array(image_test)
np.shape(image_test)

image_test = np.expand_dims(image_test, axis=0)
np.shape(image_test)

image_test = tf.keras.applications.resnet50.preprocess_input(image_test)

class_names = sorted(train_generator.class_indices.items(), key = lambda pair:pair[1])

class_names

class_names = np.array([key.title() for key, value in class_names])

class_names

predict_res = model.predict_generator(image_test)
predict_id = np.argmax(predict_res)
predict_label = class_names[predict_id]

predict_id

predict_label

print(predict_res)